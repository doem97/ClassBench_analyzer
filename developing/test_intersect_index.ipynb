{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finished code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import ipaddress\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "from networkx.algorithms.cluster import average_clustering\n",
    "from networkx.algorithms.components import *\n",
    "from networkx.algorithms.dag import (dag_longest_path_length,\n",
    "\t\t\t\t\t\t\t\t\t is_directed_acyclic_graph)\n",
    "import networkx.algorithms.approximation as approx\n",
    "from networkx.algorithms.connectivity import node_connectivity, edge_connectivity\n",
    "\n",
    "from modules import Rule\n",
    "from modules_hit import Rule_hit\n",
    "from utils import construct_graph\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def load_ruleset(fname, except_zero = True, random_priority = 0):\n",
    "\t\"\"\" Load ruleset from ClassBench filter file \"\"\"\n",
    "\t\"\"\"\n",
    "\t(expect_zero = True): due to zero nodes(0.0.0.0/n) causes huge computing resource, you can exclude all zero nodes here.\n",
    "\t(random_priorit = n): from 0 to n. if n = 0, use the sequence of the ruleset as each rule's priority.\n",
    "\t\"\"\"\n",
    "\truleset = []\n",
    "\twith open(fname, 'r') as f:\n",
    "\t\tfor n, line in enumerate(f):\n",
    "\t\t\t# LINE FORMAT\n",
    "\t\t\t# @sip_network dip_network sp_low : sp_high dp_low: dp_high protocal/protocol_mask xxx/xxx\n",
    "\t\t\ttok = line.strip().split('\\t')\n",
    "\t\t\trule = Rule_hit()\n",
    "\t\t\tsip = ipaddress.ip_network(tok[0][1:])\n",
    "\t\t\tdip = ipaddress.ip_network(tok[1])\n",
    "\t\t\tsp = tok[2].split(':')\n",
    "\t\t\tdp = tok[3].split(':')\n",
    "\t\t\tprotocol = tok[4].split('/')\n",
    "\t\t\t\n",
    "\t\t\tif except_zero:\n",
    "\t\t\t\tif int(sip[0]) == 0 or int(dip[0]) == 0:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t#sip[0] : given a IP/mask, upper bound of IP address\n",
    "\t\t\t#sip[-1] : given a IP/mask, lower bound of IP address\n",
    "\t\t\trule.sip_low = int(sip[0])\n",
    "\t\t\trule.sip_high = int(sip[-1])\n",
    "\t\t\trule.dip_low = int(dip[0])\n",
    "\t\t\trule.dip_high = int(dip[-1])\n",
    "\t\t\trule.sp_low, rule.sp_high = int(sp[0]), int(sp[1])\n",
    "\t\t\trule.dp_low, rule.dp_high = int(dp[0]), int(dp[1])\n",
    "\t\t\trule.protocol_val, rule.protocol_mask = int(protocol[0], 16), int(protocol[1], 16)\n",
    "\n",
    "\t\t\tif random_priority:\n",
    "\t\t\t\trule.priority = int(random.randint(0, random_priority))\n",
    "\t\t\telse:\n",
    "\t\t\t\trule.priority = n\n",
    "\t\t\truleset.append(rule)\n",
    "\treturn ruleset\n",
    "\n",
    "def all_path_lenth(graph):\n",
    "\tpaths_len = []\n",
    "\tfor idx_s in [idx for idx,i in enumerate(list(dict(G.in_degree()).values())) if (i == 0 and G.out_degree(idx) != 0)]:\n",
    "\t\tfor idx_d in [idx for idx,i in enumerate(list(dict(G.out_degree()).values())) if (i == 0 and G.in_degree(idx) != 0)]:\n",
    "\t\t\tif nx.has_path(G,idx_s, idx_d):\n",
    "\t\t\t\tl = list(nx.all_simple_paths(G, source=idx_s, target=idx_d))\n",
    "\t\t\t\tpaths_len.append(len(l))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcontinue\n",
    "\treturn np.array(paths_len)\n",
    "\n",
    "def rule_intersect(rule_a, rule_b):\n",
    "    \"\"\" Decide if two rules intersect \"\"\"\n",
    "    ab_sip_split = get_split(rule_a.sip_low, rule_a.sip_high, rule_b.sip_low, rule_b.sip_high)\n",
    "    if not ab_sip_split:\n",
    "        return False\n",
    "\n",
    "    ab_dip_split = get_split(rule_a.dip_low, rule_a.dip_high, rule_b.dip_low, rule_b.dip_high)\n",
    "    if not ab_dip_split:\n",
    "        return False\n",
    "\n",
    "    ab_sp_split = get_split(rule_a.sp_low, rule_a.sp_high, rule_b.sp_low, rule_b.sp_high)\n",
    "    if not ab_sp_split:\n",
    "        return False\n",
    "\n",
    "    ab_dp_split = get_split(rule_a.dp_low, rule_a.dp_high, rule_b.dp_low, rule_b.dp_high)\n",
    "    if not ab_dp_split:\n",
    "        return False\n",
    "    \n",
    "    temp_ruleset_a = split_to_rule(ab_sip_split[0], ab_dip_split[0], ab_sp_split[0], ab_dp_split[0], rule_a.hit_time, rule_a.protocol_val, rule_a.protocol_mask, rule_a.priority)\n",
    "    # the a rule will be divided into many rules, temp_ruleset_a is a list contain them\n",
    "    temp_ruleset_b = split_to_rule(ab_sip_split[1], ab_dip_split[1], ab_sp_split[1], ab_dp_split[1], rule_b.hit_time, rule_b.protocol_val, rule_b.protocol_mask, rule_b.priority)\n",
    "    temp_ruleset = merge2cube(temp_ruleset_a, temp_ruleset_b)\n",
    "    return temp_ruleset\n",
    "\n",
    "def get_split(a_low, a_high, b_low, b_high):\n",
    "    # receives two ranges, if they has intersect, function returns the intersection (a_split, b_split)\n",
    "    # each split at most will have three parts\n",
    "    # else return False\n",
    "    \"\"\"warning: caution of (0,4)(4,6)\"\"\"\n",
    "    if (a_high >= b_low and b_high >= a_low):\n",
    "        temp_list = [a_low, a_high, b_low, b_high]\n",
    "        temp_list.sort()\n",
    "        a_split = split_range([a_low, a_high], [temp_list[1], temp_list[2]])\n",
    "        b_split = split_range([b_low, b_high], [temp_list[1], temp_list[2]])\n",
    "        return (a_split, b_split)\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def split_range(mother_range, child_range):\n",
    "    \"\"\"receives two lists: mother_range[low, high], child_range[low, high]\"\"\"\n",
    "    \"\"\"return a list that contain 1, 2 or 3 tuples\"\"\"\n",
    "    \"\"\"WARNING: only mother and child counts, so make sure of it before call the function\"\"\"\n",
    "    range_split = [(child_range[0], child_range[1])]\n",
    "    if mother_range[1] > child_range[1]:\n",
    "        range_split.append((child_range[1]+1, mother_range[1]))\n",
    "    if mother_range[0] < child_range[0]:\n",
    "        range_split.insert(0,(mother_range[0], child_range[0]-1))\n",
    "    return range_split\n",
    "\n",
    "def same_rule(rule_a, rule_b):\n",
    "    \"\"\"only counts sip dip sp dp\"\"\"\n",
    "    if ((rule_a.sip_low == rule_b.sip_low) and (rule_a.sip_high == rule_b.sip_high)):\n",
    "        if ((rule_a.dip_low == rule_b.dip_low) and (rule_a.dip_high == rule_b.dip_high)):\n",
    "            if ((rule_a.sp_low == rule_b.sp_low) and (rule_a.sp_high == rule_b.sp_high)):\n",
    "                if ((rule_a.dp_low == rule_b.dp_low) and (rule_a.dp_high == rule_b.dp_high)):\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def mv_dipulation(ruleset):\n",
    "    \"\"\"Designed for small scale ruleset: remove duplicated rules. It will change the sequence\"\"\"\n",
    "    temp_ruleset = []\n",
    "    for index, i in enumerate(ruleset):\n",
    "        for j in range(index+1, len(ruleset)):\n",
    "            if same_rule(ruleset[index], ruleset[j]):\n",
    "                break\n",
    "        else:\n",
    "            temp_ruleset.append(ruleset[index])\n",
    "    else:\n",
    "        return temp_ruleset\n",
    "    \n",
    "def merge2cube(ruleset_a, ruleset_b):\n",
    "    \"\"\"the same cube has hit_time * 2\"\"\"\n",
    "    \"\"\"only designed for 2 intersect rules and returns a merged non-exclution group\"\"\"\n",
    "    temp_ruleset = []\n",
    "    temp_merge = ruleset_a + ruleset_b\n",
    "    for i, sing_rule in enumerate(temp_merge):\n",
    "        for j in range(i+1, len(temp_merge)):\n",
    "            if same_rule(temp_merge[i], temp_merge[j]):\n",
    "                temp_merge[j].hit_time += temp_merge[i].hit_time\n",
    "                break\n",
    "        else:\n",
    "            temp_ruleset.append(sing_rule)\n",
    "    else:\n",
    "        return temp_ruleset\n",
    "    \n",
    "def split_to_rule(sip, dip, sp, dp, hit_time, protocol_val, protocol_mask, priority):\n",
    "    # each parameter is a [(), (), ()] kind (can be 1, 2 or 3)\n",
    "    hit_list = []\n",
    "    for sip_range in sip:\n",
    "        for dip_range in dip:\n",
    "            for sp_range in sp:\n",
    "                for dp_range in dp:\n",
    "                    hit_list.append(construct_rule_from_ip_port(sip_range, dip_range, sp_range, dp_range, hit_time, protocol_val, protocol_mask, priority))\n",
    "    return hit_list\n",
    "                    \n",
    "def construct_rule_from_ip_port(sip_range, dip_range, sp_range, dp_range, hit_time, protocol_val, protocol_mask, priority):\n",
    "    temp_rule = Rule_hit()\n",
    "    temp_rule.sip_low, temp_rule.sip_high = sip_range[0], sip_range[1]\n",
    "    temp_rule.dip_low, temp_rule.dip_high = dip_range[0], dip_range[1]\n",
    "    temp_rule.sp_low, temp_rule.sp_high = sp_range[0], sp_range[1]\n",
    "    temp_rule.dp_low, temp_rule.dp_high = dp_range[0], dp_range[1]\n",
    "    temp_rule.hit_time = hit_time\n",
    "    temp_rule.protocol_val = protocol_val\n",
    "    temp_rule.protocol_mask = protocol_mask\n",
    "    temp_rule.priority = priority\n",
    "    return temp_rule\n",
    "\n",
    "def flush_ruleset(ruleset):\n",
    "    \"\"\"split a random ruleset\"\"\"\n",
    "    G = construct_graph(ruleset)\n",
    "    temp_ruleset = []\n",
    "    temp_list = list(nx.weakly_connected_components(G))\n",
    "    for i in temp_list:\n",
    "        if len(i) == 1:\n",
    "            for t in i:\n",
    "                temp_ruleset.append(ruleset[t])\n",
    "        else:\n",
    "            temp_child_ruleset = []\n",
    "            for t in i:\n",
    "                temp_child_ruleset.append(ruleset[t])\n",
    "            # temp_child_ruleset don't have non-inter cube\n",
    "            solve_interarea_once(temp_child_ruleset)\n",
    "            temp_child_ruleset = flush_ruleset(temp_child_ruleset)\n",
    "            temp_ruleset.extend(temp_child_ruleset)\n",
    "    return temp_ruleset\n",
    "\n",
    "def solve_interarea_once(ruleset):\n",
    "    # flush a fully intersect area and return a non-inter area\n",
    "    for index_i, i in enumerate(ruleset):\n",
    "        for index_j in range(index_i+1, len(ruleset)):\n",
    "            temp_inter = rule_intersect(i,ruleset[index_j])\n",
    "            if temp_inter:\n",
    "                global hit_1_time\n",
    "                hit_1_time += 1\n",
    "                del ruleset[index_i]\n",
    "                del ruleset[index_j-1]\n",
    "                ruleset.extend(temp_inter)\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huge group workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_ruleset_from_set(node_num_set, ruleset):\n",
    "    temp_ruleset = []\n",
    "    for i in node_num_set:\n",
    "        temp_ruleset.append(ruleset[i])\n",
    "    return temp_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load rules from ClassBench filter file, build a graph,\n",
    "and print graph statistics \"\"\"\n",
    "\n",
    "ruleset = load_ruleset(\"../data/acl filters/MyFilters10k_1.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = construct_graph(ruleset)\n",
    "list_temp = list(nx.weakly_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in list_temp:\n",
    "    if len(i)>100:\n",
    "        t.append(construct_ruleset_from_set(i, ruleset))\n",
    "for i in t:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = t[1]\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hit_1_time = 0\n",
    "temp_ruleset = flush_ruleset(temp)\n",
    "print(hit_1_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temp code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_ruleset_once(ruleset):\n",
    "    for index_i, i in enumerate(ruleset):\n",
    "        for index_j in range(index_i+1, len(ruleset)):\n",
    "            temp_set = rule_intersect(i,ruleset[index_j])\n",
    "            if temp_set:\n",
    "                del ruleset[index_i]\n",
    "                del ruleset[index_j-1]\n",
    "                ruleset.extend(temp_set)\n",
    "                return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def flush_ruleset(ruleset):\n",
    "    if not flush_ruleset_once(ruleset):\n",
    "        flush_ruleset(ruleset)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflush_ruleset(ruleset_a):\n",
    "    \"\"\"ruleset_a flush ruleset_b\"\"\"\n",
    "    temp_ruleset = []\n",
    "    for coming_rule in ruleset_a:\n",
    "        if temp_ruleset:\n",
    "            temp_ruleset = rule_flush_ruleset(coming_rule, temp_ruleset)\n",
    "            for i in temp_ruleset:\n",
    "                print(i.sip_low)\n",
    "            print(\"wa\")\n",
    "        else:\n",
    "            temp_ruleset.append(coming_rule)\n",
    "            for i in temp_ruleset:\n",
    "                print(i.sip_low)\n",
    "            print(\"wa\")\n",
    "    return temp_ruleset\n",
    "\n",
    "def rule_flush_ruleset(rule, ruleset):\n",
    "    new_ruleset = []\n",
    "    for exist_rule in ruleset:\n",
    "        temp_inter = rule_intersect(rule, exist_rule)\n",
    "        print(temp_inter)\n",
    "        print(\"wa\")\n",
    "        if temp_inter:\n",
    "            new_ruleset.extend(temp_inter)\n",
    "        else:\n",
    "            new_ruleset.append(exist_rule)\n",
    "        \n",
    "    return new_ruleset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# developing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut2points(ruleset):\n",
    "    sip = []\n",
    "    dip = []\n",
    "    sp = []\n",
    "    dp = []\n",
    "    for i in ruleset:\n",
    "        sip.append(i.sip_low)\n",
    "        sip.append(i.sip_high)\n",
    "        dip.append(i.dip_low)\n",
    "        dip.append(i.dip_high)\n",
    "        sp.append(i.sp_low)\n",
    "        sp.append(i.sp_high)\n",
    "        dp.append(i.dp_low)\n",
    "        dp.append(i.dp_high)\n",
    "    return sorted(set(sip)), sorted(set(dip)), sorted(set(sp)), sorted(set(dp))\n",
    "\n",
    "def list2mapping(a):\n",
    "    mapping = {}\n",
    "    for i,v in enumerate(a):\n",
    "        mapping[v] = i\n",
    "    return mapping\n",
    "\n",
    "def get_point_index(rule,sip_map, dip_map, sp_map, dp_map):\n",
    "    sip_low = sip_map[rule.sip_low]\n",
    "    sip_high = sip_map[rule.sip_high]\n",
    "    dip_low = dip_map[rule.dip_low]\n",
    "    dip_high = dip_map[rule.dip_high]\n",
    "    sp_low = sp_map[rule.sp_low]\n",
    "    sp_high = sp_map[rule.sp_high]\n",
    "    dp_low = dp_map[rule.dp_low]\n",
    "    dp_high = dp_map[rule.dp_high]\n",
    "    return sip_low, sip_high, dip_low, dip_high, sp_low, sp_high, dp_low, dp_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset = load_ruleset(\"../data/fw filters/MyFilters10k_{}.txt\".format(3), False)\n",
    "sip, dip, sp, dp = cut2points(ruleset) # returns a set\n",
    "sip_len = len(sip)\n",
    "dip_len = len(dip)\n",
    "sp_len = len(sp)\n",
    "dp_len = len(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sip_map = list2mapping(sip)\n",
    "dip_map = list2mapping(dip)\n",
    "sp_map = list2mapping(sp)\n",
    "dp_map = list2mapping(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5484,10321,15,45\n"
     ]
    }
   ],
   "source": [
    "print(\"{},{},{},{}\".format(sip_len, dip_len, sp_len, dp_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = np.zeros((sip_len-1, dip_len-1, sp_len-1, dp_len-1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5483, 10320, 14, 44)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 657 µs, sys: 51 µs, total: 708 µs\n",
      "Wall time: 30.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in ruleset[0:100]:\n",
    "    sip_low, sip_high, dip_low, dip_high, sp_low, sp_high, dp_low, dp_high = get_point_index(i, sip_map, dip_map, sp_map, dp_map)\n",
    "    temp_1[sip_low:sip_high, dip_low:dip_high, sp_low:sp_high, dp_low:dp_high] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 1 µs, total: 9 µs\n",
      "Wall time: 10.5 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]],\n",
       "\n",
       "        [[0, 0],\n",
       "         [0, 0]]]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "temp_1[2334:2337, 4411:4414, 3:5, 13:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(temp_1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sip_low, sip_high, dip_low, dip_high, sp_low, sp_high, dp_low, dp_high = get_point_index(ruleset[0],sip_map, dip_map, sp_map, dp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2335,2336,4412,4413,4,4,14,14\n"
     ]
    }
   ],
   "source": [
    "print(\"{},{},{},{},{},{},{},{}\".format(sip_low, sip_high, dip_low, dip_high, sp_low, sp_high, dp_low, dp_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2:4, 2:3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1[2333:2338, 4412:4414, 2:5, 12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = np.zeros((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(tick[2:4, 2:4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0,10):\n",
    "    temp_1 = np.add(temp_1[2400:4000, 2000:6000,35:45,1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a = np.ones((4000-2400, 6000-2000, 1, 46-36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.add(temp_num, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "for i in range(0, 7518420):\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset = load_ruleset(\"../data/fw filters/MyFilters10k_1.txt\", True)\n",
    "cut_sip_1d(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division = len(sip)*len(dip)*len(sp)*len(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_group(G):\n",
    "    temp = 0\n",
    "    temp_list = list(nx.weakly_connected_components(G))\n",
    "    for i in temp_list:\n",
    "        if len(i)>temp:\n",
    "            temp = len(i)\n",
    "    return temp\n",
    "\n",
    "for strs in ['acl', 'fw', 'ipc']:\n",
    "    for j in range(1, 11):\n",
    "        i = 10\n",
    "        path = \"../data/{} filters/MyFilters{}\".format(strs,i) + \"k_{}.txt\".format(j)\n",
    "        print(\"{},{}\".format(i,j))\n",
    "        ruleset = load_ruleset(path)\n",
    "        G = construct_graph(ruleset)\n",
    "        max_group = find_max_group(G)\n",
    "        print(\"----------->{}\".format(max_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_ruleset(ruleset):\n",
    "    \"\"\"split a random ruleset\"\"\"\n",
    "    G = construct_graph(ruleset)\n",
    "    temp_ruleset = []\n",
    "    temp_list = list(nx.weakly_connected_components(G))\n",
    "    for i in temp_list:\n",
    "        if len(i) == 1:\n",
    "            for t in i:\n",
    "                temp_ruleset.append(ruleset[t])\n",
    "        else:\n",
    "            temp_child_ruleset = []\n",
    "            for t in i:\n",
    "                temp_child_ruleset.append(ruleset[t])\n",
    "            print(\"before len is: {}\",format([n.hit_time for n in temp_child_ruleset]))\n",
    "            for h in temp_child_ruleset:\n",
    "                print(\"sip_low: {}, sip_high: {}\".format(h.sip_low, h.sip_high))\n",
    "            solve_fully_intersect_area(temp_child_ruleset) # temp_child_ruleset don't have non-inter cube\n",
    "            print(\"after len is: {}\",format([n.hit_time for n in temp_child_ruleset]))\n",
    "            for h in temp_child_ruleset:\n",
    "                print(\"sip_low: {}, sip_high: {}\".format(h.sip_low, h.sip_high))\n",
    "            temp_ruleset.extend(temp_child_ruleset)\n",
    "    return temp_ruleset\n",
    "\n",
    "def solve_fully_intersect_area_1(ruleset):\n",
    "    # flush a fully intersect area and return a non-inter area\n",
    "    for index_i, i in enumerate(ruleset):\n",
    "        for index_j in range(index_i+1, len(ruleset)):\n",
    "            temp_inter = rule_intersect(i,ruleset[index_j])\n",
    "            if temp_inter:\n",
    "                del ruleset[index_i]\n",
    "                del ruleset[index_j-1]\n",
    "                ruleset.extend(temp_inter)\n",
    "                return\n",
    "\n",
    "def solve_fully_intersect_area(ruleset):\n",
    "    solve_fully_intersect_area_1(ruleset)\n",
    "    temp_ruleset = flush_ruleset(ruleset)\n",
    "    ruleset = temp_ruleset\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = construct_graph(ruleset)\n",
    "list_temp = list(nx.weakly_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in list_temp:\n",
    "    if len(i) > 1:\n",
    "        t = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ruleset = []\n",
    "for k in t:\n",
    "    temp_ruleset.append(ruleset[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(temp_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_ruleset = flush_ruleset(temp_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_list = flush_ruleset(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = construct_graph(temp_list)\n",
    "list_temp = list(nx.weakly_connected_components(GG))\n",
    "\n",
    "for i in list_temp:\n",
    "    if len(i) > 1:\n",
    "        print(\"wa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = list(nx.weakly_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_ruleset = []\n",
    "temp_list = list(nx.weakly_connected_components(G))\n",
    "for i in temp_list:\n",
    "    if len(i) == 1:\n",
    "        for t in i:\n",
    "            temp_ruleset.append(ruleset[t])\n",
    "    else:\n",
    "        temp_child_ruleset = []\n",
    "        for t in i:\n",
    "            temp_child_ruleset.append(ruleset[t])\n",
    "        flush_ruleset(temp_child_ruleset)\n",
    "        temp_ruleset.extend(temp_child_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load rules from ClassBench filter file, build a graph,\n",
    "and print graph statistics \"\"\"\n",
    "\n",
    "ruleset = load_ruleset(\"../data/acl filters/MyFilters1k_1.txt\")\n",
    "G = construct_graph(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_ruleset = []\n",
    "temp_list = list(nx.weakly_connected_components(G))\n",
    "for i in temp_list:\n",
    "    if len(i) == 1:\n",
    "        for t in i:\n",
    "            temp_ruleset.append(ruleset[t])\n",
    "    else:\n",
    "        temp_child_ruleset = []\n",
    "        for t in i:\n",
    "            temp_child_ruleset.append(ruleset[t])\n",
    "        flush_ruleset(temp_child_ruleset)\n",
    "        temp_ruleset.extend(temp_child_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = construct_graph(temp_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(nx.weakly_connected_components(G)):\n",
    "    if len(i) > 1:\n",
    "        print(\"fxxk!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_group_eat(rule, ex_ruleset):\n",
    "    \"\"\"get a exclution ruleset and return a exclution ruleset combined with a new rule\"\"\"\n",
    "    temp_ex_group = ex_ruleset\n",
    "    for i in ex_ruleset:\n",
    "        temp_inter = rule_intersect(rule, i)\n",
    "        if not temp_inter:\n",
    "            continue\n",
    "        else:\n",
    "            ex_ruleset.extend(temp_inter)\n",
    "            if is_ex_group(temp_ex_group):\n",
    "                continue\n",
    "            else:\n",
    "                ex_ruleset = flush_non_ex_group(ex_ruleset) # ！！\n",
    "    return ex_ruleset\n",
    "\n",
    "def flush_non_ex_group(ruleset):\n",
    "    \"\"\"receive a non-exgroup and return a exgroup\"\"\"\n",
    "    temp_ex_group = []\n",
    "    temp_ex_group.append(ruleset[0])\n",
    "    for index, i in enumerate(ruleset[1:]):\n",
    "        temp_ex_group = ex_group_eat(i, temp_ex_group)\n",
    "        \n",
    "def is_ex_group(random_ruleset):\n",
    "    \"\"\"wait for develop\"\"\"\n",
    "    for index, i in enumerate(random_ruleset):\n",
    "        for j in range(index+1, len(random_ruleset)):\n",
    "            if rule_intersect(i, random_ruleset[j]):\n",
    "                return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_ruleset(ruleset):\n",
    "    temp_1 = ruleset[0]\n",
    "    temp_2 = ruleset[1]\n",
    "    temp_non_inter_ruleset = rule_intersect(tmep_1, temp_2)\n",
    "    for i in ruleset[2:]:\n",
    "        temp_non_inter_ruleset = non_inter_ruleset_eat_1(temp_non_inter_ruleset, i)\n",
    "    return temp_non_inter_ruleset\n",
    "\n",
    "def non_inter_ruleset_eat_1(ruleset, rule):\n",
    "    temp_ruleset = ruleset\n",
    "    if has_inter_relation(ruleset, rule):\n",
    "        temp_ruleset = flush_ruleset(temp_ruleset)\n",
    "    else:\n",
    "        wait()\n",
    "    return temp_ruleset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = construct_graph(temp_ruleset)\n",
    "list_temp = list(nx.weakly_connected_components(GG))\n",
    "\n",
    "for i in list_temp:\n",
    "    if len(i) > 1:\n",
    "        print(\"wa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_1 = ruleset[0]\n",
    "rule_2 = ruleset[1]\n",
    "rule_3 = ruleset[2]\n",
    "\n",
    "rule_1.sip_low, rule_1.sip_high = 0, 58888\n",
    "rule_1.dip_low, rule_1.dip_high = 0, 58888\n",
    "rule_1.sp_low, rule_1.sp_high = 0, 65535\n",
    "rule_1.dp_low, rule_1.dp_high = 0, 65535\n",
    "\n",
    "rule_2.sip_low, rule_2.sip_high = 2000, 2399\n",
    "rule_2.dip_low, rule_2.dip_high = 0, 58888\n",
    "rule_2.sp_low, rule_2.sp_high = 0, 65535\n",
    "rule_2.dp_low, rule_2.dp_high = 0, 65535\n",
    "\n",
    "rule_3.sip_low, rule_3.sip_high = 2000, 2399\n",
    "rule_3.dip_low, rule_3.dip_high = 0, 58888\n",
    "rule_3.sp_low, rule_3.sp_high = 0, 65535\n",
    "rule_3.dp_low, rule_3.dp_high = 0, 65535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_ruleset = [rule_1, rule_2, rule_3]\n",
    "for i in temp_ruleset:\n",
    "    print(\"sip: {},{}   dip: {},{}   sp: {},{}   dp: {},{}\".format(i.sip_low, i.sip_high, i.dip_low, i.dip_high,\n",
    "                                                                   i.sp_low, i.sp_high, i.dp_low, i.dp_high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "temp_ruleset = flush_ruleset(temp_ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp_ruleset:\n",
    "    print(i.hit_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp_ruleset:\n",
    "    print(i)\n",
    "    print(\"hit time of this ruleset is: {}\".format(i.hit_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "is_ex_group(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(list_a):\n",
    "    del list_a[1]\n",
    "    del list_a[1]\n",
    "    return\n",
    "\n",
    "list_c = [2,1,3,4,4,5]\n",
    "test(list_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:science3]",
   "language": "python",
   "name": "conda-env-science3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
